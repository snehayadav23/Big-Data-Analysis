{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331272ce-d290-4366-ad3b-07147b020e8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331272ce-d290-4366-ad3b-07147b020e8f",
        "outputId": "b52eae0d-1a5a-41d7-cb08-658ecab7b513"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle pyspark\n",
        "!pip install findspark\n",
        "!pip install pandas==1.5.3\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1506967a-2f9a-4017-bcc2-106b7a491851",
      "metadata": {
        "id": "1506967a-2f9a-4017-bcc2-106b7a491851"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'xxxxxxxxxxxxxxxx'  \n",
        "os.environ['KAGGLE_KEY'] = 'xxxxxxxxxxxxxxxxxxxxxx' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54042cc0-c233-4de8-b382-5358f4fe2476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54042cc0-c233-4de8-b382-5358f4fe2476",
        "outputId": "0c9e0952-a79d-440c-9ac0-cc6fb2104ef7"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d asaniczka/1-3m-linkedin-jobs-and-skills-2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a7aa2c7-adb3-45ca-9b60-474c9416a382",
      "metadata": {
        "id": "7a7aa2c7-adb3-45ca-9b60-474c9416a382"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('1-3m-linkedin-jobs-and-skills-2024.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bWmWque49tQ_",
      "metadata": {
        "id": "bWmWque49tQ_"
      },
      "outputs": [],
      "source": [
        "file_path = 'dataset/job_summary.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iqxs_BhZ-Lzq",
      "metadata": {
        "id": "iqxs_BhZ-Lzq"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "import re\n",
        "import hashlib\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, MinHashLSH\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.pipeline import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xh0iGGzJlnt0",
      "metadata": {
        "id": "xh0iGGzJlnt0"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local\") \\\n",
        "        .appName(\"JobDescriptionSimilarity\") \\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Cn_GFVWlnK2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "0Cn_GFVWlnK2",
        "outputId": "fd6f7883-5ae6-48f9-8915-ff3438dc1354"
      },
      "outputs": [],
      "source": [
        "spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vSbp-yf3lnlo",
      "metadata": {
        "id": "vSbp-yf3lnlo"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"job_link\", StringType(), True),\n",
        "    StructField(\"job_summary\", StringType(), True)\n",
        "])\n",
        "\n",
        "df = spark.read \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"multiLine\", \"true\") \\\n",
        "    .option(\"escape\", \"\\\"\") \\\n",
        "    .option(\"quote\", \"\\\"\") \\\n",
        "    .schema(schema) \\\n",
        "    .csv(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y92Ec5zVl_YB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y92Ec5zVl_YB",
        "outputId": "71a61688-7403-4a57-831e-a116ac51f1c1"
      },
      "outputs": [],
      "source": [
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bs27rw1CmLXY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs27rw1CmLXY",
        "outputId": "056fbb54-058a-4e59-bfa3-317a29cd9a83"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5sn7cfyanLKB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sn7cfyanLKB",
        "outputId": "dedd44bb-e890-4a6f-fc8c-3246b19f5f98"
      },
      "outputs": [],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AHWTt-gQpKMc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHWTt-gQpKMc",
        "outputId": "e8c02165-9943-4bd5-fea5-13cf5474b888"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ISUSyX-spP6P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISUSyX-spP6P",
        "outputId": "1034c21a-4574-45db-c055-c9cf95098151"
      },
      "outputs": [],
      "source": [
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a1513e8-8ffe-41e7-bc8f-8638a9bc4df0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a1513e8-8ffe-41e7-bc8f-8638a9bc4df0",
        "outputId": "98029fb6-a5a3-4892-de5b-d1751fcc27fe"
      },
      "outputs": [],
      "source": [
        "!pip install datasketch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "orMJkYx3yAmy",
      "metadata": {
        "id": "orMJkYx3yAmy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasketch import MinHash, MinHashLSH\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(\",.!?\") for token in tokens]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mK9hybSayi8F",
      "metadata": {
        "id": "mK9hybSayi8F"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "\n",
        "\n",
        "preprocess_text_udf = udf(preprocess_text, ArrayType(StringType()))\n",
        "\n",
        "\n",
        "df = df.withColumn(\"preprocessed_text\", preprocess_text_udf(\"job_summary\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hwRv-Rha2C9z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwRv-Rha2C9z",
        "outputId": "6e12a8a3-b295-4924-d068-375273384b71"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GXo-eUX4yDBd",
      "metadata": {
        "id": "GXo-eUX4yDBd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_shingles(text, k=3):\n",
        "    tokens = preprocess_text(text)\n",
        "    shingles = set()\n",
        "    for i in range(len(tokens) - k + 1):\n",
        "        shingle = \" \".join(tokens[i:i+k])\n",
        "        shingles.add(shingle)\n",
        "    return shingles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TTAZoa7940Ny",
      "metadata": {
        "id": "TTAZoa7940Ny"
      },
      "outputs": [],
      "source": [
        "\n",
        "generate_shingles_udf = udf(lambda text: list(generate_shingles(\" \".join(text))), ArrayType(StringType()))\n",
        "\n",
        "\n",
        "df = df.withColumn(\"shingles\", generate_shingles_udf(\"preprocessed_text\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1mxtv0R348_X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mxtv0R348_X",
        "outputId": "c76a85d4-ff73-48f3-9893-208722516a6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XOLJlwAcyPfM",
      "metadata": {
        "id": "XOLJlwAcyPfM"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_minhash_signature(shingles, num_perm=128 , pd=1):\n",
        "    m = MinHash(num_perm=num_perm)\n",
        "    for shingle in shingles:\n",
        "        m.update(shingle.encode('utf8'))\n",
        "    if pd == 1:\n",
        "      return m\n",
        "    else:\n",
        "      return m.hashvalues.tolist()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hZGfqLo-5dRy",
      "metadata": {
        "id": "hZGfqLo-5dRy"
      },
      "outputs": [],
      "source": [
        "\n",
        "generate_minhash_signature_udf = udf(lambda shingles: generate_minhash_signature(shingles,pd=0), ArrayType(IntegerType()))\n",
        "\n",
        "df = df.withColumn(\"minhash_signature\", generate_minhash_signature_udf(\"shingles\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IB3Hi7hv5gSq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB3Hi7hv5gSq",
        "outputId": "8975fee2-d521-4f33-a817-740487c326d4"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FykYHETZySRl",
      "metadata": {
        "id": "FykYHETZySRl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_lsh_index(data, num_perm=128, threshold=0.5):\n",
        "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
        "    minhashes = {}\n",
        "    for index, row in data.iterrows():\n",
        "        shingles = generate_shingles(row['job_summary'])\n",
        "        minhash = generate_minhash_signature(shingles, num_perm)\n",
        "        minhashes[index] = minhash\n",
        "        lsh.insert(index, minhash)\n",
        "    return lsh, minhashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5m2j43r41bLi",
      "metadata": {
        "id": "5m2j43r41bLi"
      },
      "outputs": [],
      "source": [
        "# Function to Find similar job descriptions using LSH\n",
        "def find_similar_jobs(data, lsh, minhashes, num_perm=128):\n",
        "    similar_pairs = []\n",
        "    for index, row in data.iterrows():\n",
        "        shingles = generate_shingles(row['job_summary'])\n",
        "        minhash = generate_minhash_signature(shingles, num_perm)\n",
        "        candidates = lsh.query(minhash)\n",
        "        for candidate in candidates:\n",
        "            if candidate != index:\n",
        "                jaccard = minhashes[index].jaccard(minhashes[candidate])\n",
        "                if jaccard > 0.5:\n",
        "                    similar_pairs.append((index, candidate))\n",
        "    return similar_pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6s-JP9_2IpV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6s-JP9_2IpV",
        "outputId": "bfed2a54-ec45-4cb2-cef0-9f334fe44d3f"
      },
      "outputs": [],
      "source": [
        "\n",
        "chunk_size = 10000\n",
        "lsh = None\n",
        "minhashes = {}\n",
        "similar_pairs = []\n",
        "\n",
        "df_similar_pairs = pd.DataFrame(columns=['RowNumber1', 'JobSummary1','RowNumber2',  'JobSummary2'])\n",
        "\n",
        "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "    if lsh is None:\n",
        "        lsh, minhashes = create_lsh_index(chunk)\n",
        "    else:\n",
        "        for index, row in chunk.iterrows():\n",
        "            shingles = generate_shingles(row['job_summary'])\n",
        "            minhash = generate_minhash_signature(shingles)\n",
        "            minhashes[index] = minhash\n",
        "            lsh.insert(index, minhash)\n",
        "    for pair in find_similar_jobs(chunk, lsh, minhashes):\n",
        "        idx1, idx2 = pair\n",
        "        # Checking if the pair is already processed\n",
        "        if pair not in similar_pairs:\n",
        "            job_summary1 = chunk.iloc[idx1]['job_summary']\n",
        "            job_summary2 = chunk.iloc[idx2]['job_summary']\n",
        "            similar_pairs.append(pair)\n",
        "            df_similar_pairs = df_similar_pairs.append({\n",
        "                'RowNumber1': idx1+1,\n",
        "                'JobSummary1': job_summary1,\n",
        "                'RowNumber2': idx2+1,\n",
        "                'JobSummary2': job_summary2\n",
        "            }, ignore_index=True)\n",
        "    break\n",
        "\n",
        "print(df_similar_pairs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17hOiDSE9DeI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "17hOiDSE9DeI",
        "outputId": "e1cc18da-4a17-4b2f-f968-10d9e8f25fe2"
      },
      "outputs": [],
      "source": [
        "df_similar_pairs.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
